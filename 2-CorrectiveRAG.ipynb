{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b6ae34",
   "metadata": {},
   "source": [
    "### Corrective RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a31e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## loading all the environment variable\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "llm_model = os.getenv(\"LLM_MODEL\")\n",
    "embedding_model = os.getenv(\"EMBEDDING_MODEL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd64c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "### Build Index\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55442a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader('Medical_book.pdf')\n",
    "docs = loader.load()   # returns a list of Document objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84786f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split PDF into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f486214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "    model_kwargs={'device': 'cpu'},   # or 'cuda'\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e780ca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Add to vectorstore\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vectorstore=\u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoc_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed_model\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:807\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    804\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    805\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:155\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    146\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    147\u001b[39m \n\u001b[32m    148\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \n\u001b[32m    154\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:130\u001b[39m, in \u001b[36mHuggingFaceEmbeddings._embed\u001b[39m\u001b[34m(self, texts, encode_kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    137\u001b[39m     msg = (\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected embeddings to be a Tensor or a numpy array, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgot a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1000\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    998\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1014\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:650\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    646\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    648\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:558\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    548\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    556\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    557\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    567\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:488\u001b[39m, in \u001b[36mBertAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    479\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    486\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    487\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    498\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:387\u001b[39m, in \u001b[36mBertSdpaSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    384\u001b[39m     value_layer = curr_past_key_value.layers[\u001b[38;5;28mself\u001b[39m.layer_idx].values\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    386\u001b[39m     key_layer = (\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m         .view(bsz, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size)\n\u001b[32m    389\u001b[39m         .transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    390\u001b[39m     )\n\u001b[32m    391\u001b[39m     value_layer = (\n\u001b[32m    392\u001b[39m         \u001b[38;5;28mself\u001b[39m.value(current_states)\n\u001b[32m    393\u001b[39m         .view(bsz, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size)\n\u001b[32m    394\u001b[39m         .transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    395\u001b[39m     )\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m         \u001b[38;5;66;03m# save all key/value_layer to cache to be re-used for fast auto-regressive generation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Add to vectorstore\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51866278",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Save locally\n",
    "vectorstore.save_local('faiss_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ecf0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\n",
    "            folder_path='faiss_index',\n",
    "            embeddings=embed_model,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a08f6c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e36b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = ChatGroq(groq_api_key = groq_api_key, model_name = llm_model)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "    \n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "##chain the prompt with the LLM\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"Abdominal wall defects\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "000e602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdominal wall defects are birth (congenital) defects that allow the stomach or intestines to protrude. They are caused by the failure of the abdominal wall to close properly during fetal development, resulting in the stomach or intestines being outside of the abdomen.\n",
      "\n",
      "Causes and symptoms of abdominal wall defects are not well understood, and any symptoms the mother may have to indicate that the defects are present in the fetus are nondescript. However, at birth, the problem is obvious, and an ultrasound examination may detect the problem before birth.\n",
      "\n",
      "Abdominal wall defects are effectively treated with surgical repair, unless there are accompanying anomalies. The prognosis after surgical repair is relatively good, but 10% of those with more severe or additional abnormalities may die from it.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "\n",
    "system_message = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following retrieved context to answer the question.\n",
    "If you don't know the answer, say 'I don't know'.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", \"Retrieved document:\\n\\n{context}\\n\\nUser question:\\n{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fbfa607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s a re-written version of the question optimized for web search:\\n\\n\"What are the causes, symptoms, and treatment options for abdominal wall defects, including hernias, diastasis recti, and other related conditions?\"\\n\\nThis revised question:\\n\\n1. Adds specificity by mentioning related conditions (hernias and diastasis recti).\\n2. Includes relevant keywords (causes, symptoms, treatment options) to improve search engine results.\\n3. Provides a clear and concise description of the topic, making it easier for search engines to understand the user\\'s intent.\\n\\nThis revised question should yield more accurate and relevant search results, providing a better understanding of abdominal wall defects and related conditions.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d72a121f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f7944b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fcdf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import Document\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            transform_query_required = \"Yes\"\n",
    "            \n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83af81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"grade_documents\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32b187b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ea1ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Abdominal wall defects',\n",
       " 'generation': 'Based on the retrieved document, I can provide information about abdominal wall defects. \\n\\nAbdominal wall defects are birth (congenital) defects that allow the stomach or intestines to protrude. They occur when the abdominal wall does not develop properly, and the stomach or intestines may bulge or protrude outside the abdomen.\\n\\nCauses and symptoms:\\n\\n* The cause(s) of abdominal wall defects is unknown.\\n* Symptoms in the mother may be non-descript.\\n* At birth, the problem is obvious, as the base of the umbilical cord at the navel will bulge or may contain viscera (internal organs).\\n* An ultrasound examination may detect the problem before birth.\\n\\nDiagnosis and treatment:\\n\\n* Diagnosis can be made at birth or through an ultrasound examination before birth.\\n* Treatment is surgical repair, which is effective unless there are accompanying anomalies.\\n* The organs themselves are normal, just misplaced, but may be difficult to fit into the small abdominal cavity if the defect is large.\\n* After surgery, increased pressure in the stretched abdomen can compromise the function of the organs inside.\\n\\nPrognosis:\\n\\n* If there are no other defects, the prognosis after surgical repair is relatively good.\\n* However, 10% of those with more severe or additional abnormalities may die from it.\\n\\nPrevention:\\n\\n* Some birth defects may be preventable by early and attentive prenatal care, good nutrition, supplemental vitamins, diligent avoidance of unnecessary drugs and chemicals, and other elements of a healthy lifestyle.',\n",
       " 'web_search': 'No',\n",
       " 'documents': [Document(id='5db67819-15af-4657-ac4a-4b5d6cb632de', metadata={'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'creator': 'PyPDF', 'creationdate': '2004-12-18T17:00:02-05:00', 'moddate': '2004-12-18T16:15:31-06:00', 'source': 'Medical_book.pdf', 'total_pages': 637, 'page': 19, 'page_label': '20'}, page_content='Description\\nMany unexpected and fascinating events occur dur-\\ning the development of a fetus inside the womb. The\\nstomach and intestines begin development outside the\\nbabys abdomen and only later does the abdominal wall\\nenclose them. Occasionally, either the umbilical opening\\nis too large, or it develops improperly, allowing the bow-\\nels or stomach to remain outside or squeeze through the\\nabdominal wall.\\nCauses and symptoms\\nThere are many causes for birth defects that still\\nremain unclear. Presently, the cause(s) of abdominal wall\\ndefects is unknown, and any symptoms the mother may\\nhave to indicate that the defects are present in the fetus\\nare nondescript.\\nDiagnosis\\nAt birth, the problem is obvious, because the base of\\nthe umbilical cord at the navel will bulge or, in worse\\ncases, contain viscera (internal organs). Before birth, an\\nultrasound examination may detect the problem. It is\\nalways necessary in children with one birth defect to look\\nfor others, because birth defects are usually multiple.\\nTreatment\\nAbdominal wall defects are effectively treated with\\nsurgical repair. Unless there are accompanying anom-\\nalies, the surgical procedure is not overly complicated.\\nThe organs are normal, just misplaced. However, if the\\ndefect is large, it may be difficult to fit all the viscera into\\nthe small abdominal cavity.\\nPrognosis\\nIf there are no other defects, the prognosis after sur-\\ngical repair of this condition is relatively good. However,\\nKEY TERMS\\nHerniaMovement of a structure into a place it\\ndoes not belong.\\nUmbilical Referring to the opening in the\\nabdominal wall where the blood vessels from the\\nplacenta enter.\\nVisceraAny of the bodys organs located in the\\nchest or abdomen.\\n10% of those with more severe or additional abnormali-\\nties die from it. The organs themselves are fully function-\\nal; the difficulty lies in fitting them inside the abdomen.\\nThe condition is, in fact, a hernia requiring only replace-\\nment and strengthening of the passageway through\\nwhich it occurred. After surgery, increased pressure in\\nthe stretched abdomen can compromise the function of\\nthe organs inside.\\nPrevention\\nSome, but by no means all, birth defects are pre-\\nventable by early and attentive prenatal care, good nutri-\\ntion, supplemental vitamins , diligent avoidance of all\\nunnecessary drugs and chemicalsespecially tobacco\\nand other elements of a healthy lifestyle.\\nResources\\nPERIODICALS\\nDunn, J. C., and E. W. Fonkalsrud. Improved Survival of\\nInfants with Omphalocele.American Journal of Surgery\\n173 (April 1997): 284-7.\\nLanger, J. C. Gastroschisis and Omphalocele.Seminars in\\nPediatric Surgery5 (May 1996): 124-8.\\nJ. Ricker Polsdorfer, MD\\nAbnormal heart rhythms see Arrhythmias\\nABO blood typing see Blood typing and\\ncrossmatching\\nABO incompatibility see Erythroblastosis\\nfetalis\\nAbortion, habitual see Recurrent\\nmiscarriage\\nAbortion, partial birth\\nDefinition\\nPartial birth abortion is a method of late-term abor-\\ntion that terminates a pregnancy and results in the death\\nand intact removal of a fetus. This procedure is most\\ncommonly referred to as intact dilatation and extraction\\n(D & X).\\nPurpose\\nPartial birth abortion, or D&X, is performed to end a\\npregnancy and results in the death of a fetus, typically in\\nGALE ENCYCLOPEDIA OF MEDICINE 26\\nAbortion, partial birth\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 6'),\n",
       "  Document(id='81d702cf-155d-4e3d-8e7d-e9fe2625baa6', metadata={'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'creator': 'PyPDF', 'creationdate': '2004-12-18T17:00:02-05:00', 'moddate': '2004-12-18T16:15:31-06:00', 'source': 'Medical_book.pdf', 'total_pages': 637, 'page': 18, 'page_label': '19'}, page_content='zine (October 1992): 5.\\nFreundlich, Naomi. Ultrasound: Whats Wrong with this Pic-\\nture? Business Week(15 September 1997): 84-5.\\nMcDonagh, D. Brian. Ultrasound: Unsung Medical Hero.\\nUSA Today Magazine(September 1996): 66-7.\\nMurray, Maxine. Basics of Ultrasonography.Student British\\nMedical Journal (August 1996): 269-72.\\nTait, N., and J. M. Little. The Treatment of Gallstones.\\nBritish Medical Journal (8 July 1995): 99-105.\\nORGANIZATIONS\\nAmerican College of Gastroenterology. 4900 B South 31st St.,\\nArlington, V A 22206-1656. (703) 820-7400. <http://www.\\nacg.gi.org>.\\nAmerican Institute of Ultrasound in Medicine. 14750 Sweitzer\\nLane, Suite 100, Laurel, MD 20707-5906. (800) 638-\\n5352. <http://www.aium.org>.\\nAmerican Society of Radiologic Technologists. 15000 Central\\nAve., SE, Albuquerque, NM 87123-3917. (505) 298-4500.\\n<http://www.asrt.org>.\\nKurt Richard Sternlof\\nAbdominal wall defects\\nDefinition\\nAbdominal wall defects are birth (congenital)\\ndefects that allow the stomach or intestines to protrude.\\nGALE ENCYCLOPEDIA OF MEDICINE 2 5\\nAbdominal wall defects\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 5')]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"question\":\"Abdominal wall defects\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b53a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.Vectorstore_Builder.faiss_store import FAISSStore\n",
    "\n",
    "from src.Vectorstore_Builder.hf_embedding import HFEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ef21f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FAISS index loaded from: faiss_index\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m retriever = faiss_store.get_retriever(vectordb)\n\u001b[32m     12\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mAbdominal wall defects\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m docs = \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(docs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\langchain_core\\retrievers.py:216\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    214\u001b[39m kwargs_ = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    220\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **kwargs_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1032\u001b[39m, in \u001b[36mVectorStoreRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1030\u001b[39m kwargs_ = \u001b[38;5;28mself\u001b[39m.search_kwargs | kwargs\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1032\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity_score_threshold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1034\u001b[39m     docs_and_similarities = (\n\u001b[32m   1035\u001b[39m         \u001b[38;5;28mself\u001b[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001b[32m   1036\u001b[39m             query, **kwargs_\n\u001b[32m   1037\u001b[39m         )\n\u001b[32m   1038\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:643\u001b[39m, in \u001b[36mFAISS.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    624\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    625\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    629\u001b[39m     **kwargs: Any,\n\u001b[32m    630\u001b[39m ) -> List[Document]:\n\u001b[32m    631\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    632\u001b[39m \n\u001b[32m    633\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    641\u001b[39m \u001b[33;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[32m    642\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:516\u001b[39m, in \u001b[36mFAISS.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    500\u001b[39m \n\u001b[32m    501\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    513\u001b[39m \u001b[33;03m    L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[32m    514\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    515\u001b[39m embedding = \u001b[38;5;28mself\u001b[39m._embed_query(query)\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score_by_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:417\u001b[39m, in \u001b[36mFAISS.similarity_search_with_score_by_vector\u001b[39m\u001b[34m(self, embedding, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._normalize_L2:\n\u001b[32m    416\u001b[39m     faiss.normalize_L2(vector)\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m scores, indices = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m docs = []\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaypr_ughx7yt\\OneDrive\\Desktop\\Data Science Project working\\AI Doctor\\doctorenv\\Lib\\site-packages\\faiss\\class_wrappers.py:349\u001b[39m, in \u001b[36mhandle_Index.<locals>.replacement_search\u001b[39m\u001b[34m(self, x, k, params, D, I, numeric_type)\u001b[39m\n\u001b[32m    347\u001b[39m n, d = x.shape\n\u001b[32m    348\u001b[39m x = np.ascontiguousarray(x, _numeric_to_str(numeric_type))\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m d == \u001b[38;5;28mself\u001b[39m.d\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m k > \u001b[32m0\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m D \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "embedding_loader = HFEmbedding()\n",
    "embedding_model = embedding_loader.load()\n",
    "\n",
    "\n",
    "# vectordb =  IndexBuilder(\"Medical_book.pdf\").build_index()\n",
    "\n",
    "faiss_store = FAISSStore(embedding_model, index_path=\"faiss_index\")\n",
    "vectordb = faiss_store.load()\n",
    "\n",
    "retriever = faiss_store.get_retriever(vectordb)\n",
    "\n",
    "question = \"Abdominal wall defects\"\n",
    "docs = retriever.invoke(question)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba527efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doctorenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
